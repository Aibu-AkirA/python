{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# １章　人工知能の基礎知識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01．人工知能とは\n",
    "- 人工知能の定義はあいまいけど「人間と同じような知的処理を行うことのできる技術や機械」であることです。\n",
    "- 分類方法\n",
    "    - 強い人工知能：知能そのものを模倣、人間と同じような認知的状態の持っている機械(ドラえもん、アトム)、圧倒的な計算能力<br>\n",
    "    - 弱い人工知能：人間の行動を模倣することで人間の能力の一部を代替する機械\n",
    "    - 汎用人工知能\n",
    "    - 特化型人工知能\n",
    "    - 人工知能発展段階\n",
    "        - 制御プログラム➞古典的AI➞機械学習➞深層学習\n",
    "        \n",
    "    \n",
    "- まとめ\n",
    "    - 人工知能のものの定義は難しいため、用途に分けて考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02．機械学習（ML）とは\n",
    "- 人工知能のカギとなる機械学習\n",
    "    - 機械学習：入力されたデータをもとに、最も正しい振る舞いをするパラメータを自動的に決定できるため、人工知能発展のカギとみられます。\n",
    "    - ビッグデータ\n",
    "- 機械学習のポロセス\n",
    "    - 学習モデル：あるデータを入力すると、より適切な意思決定のためのデータを出力してくれる、いわば人工知能の脳のこと\n",
    "- 機械学習が扱う問題（分類と回帰）\n",
    "    - 分類：データがどの種類に属するかを見せる\n",
    "    - 回帰：データの傾向を見せる\n",
    "    - ![img1](img1.jpg)\n",
    "    \n",
    "- まとめ\n",
    "    - 機械学習の問題は大きく分類、回帰に分けられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03．ディープラーニング（DL）とは\n",
    "- 認識にすぐれたディープラーニング\n",
    "    - ディープラーニング：脳の神経回路を模したニューラルネットワーク学習モデルを用いる機械学習\n",
    "- Googleの猫とニューラルネットワーク\n",
    "    - ![img2](img2.jpg)\n",
    "\n",
    "- まとめ\n",
    "    - ディープラーニングは特徴量を自動で算出するのが画期的\n",
    "    - 画像認識分野では人間をすでに上回っている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04．人工知能と機械学習が普及するまで\n",
    "- もはや目新しい言葉ではない？\n",
    "    - ![img3](img3.jpg)\n",
    "- 第１次人工知能ブーム\n",
    "    - 1950年代から1960年代までオセロや囲碁など、狭いルールで運用されるゲームが研究対象\n",
    "- 第２次人工知能ブーム\n",
    "    - 1980年代の★エキスパートシステム★：あらかじめインプットされている専門家の知識と、現在の状況を表すデータをもとに推論結果を導く\n",
    "- 第３次人工知能ブーム\n",
    "    - ソフトコンピューティング：生命の柔軟性を模倣した計算方\n",
    "        - ニューラルネットワーク、★ファジィ理論★、遺伝的アルゴリズム、強化学習\n",
    "    - 2010年代\n",
    "        - Google、Amazon、Microsoft\n",
    "- 処理を誰でもどこでも行えるようになったことが、人工知能普及のきっかけ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ２章　機械学習の基礎知識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05．教師あり学習のしくみ\n",
    "- 教師あり学習とは\n",
    "    - 正解となる答えが含まれたデータのモデルに学習させる方法のこと\n",
    "    - モデル：人工知能の脳\n",
    "    - ラベル：正解となる答え\n",
    "    - 最終的な目標：ラベルのないデータ（テストデータ）を正解させること\n",
    "- 分類と回帰\n",
    "    - 分類：カテゴリーで\n",
    "        - カテゴリー：連続した数値✕（離散値）、大小や順序✕\n",
    "    - 回帰：連続した数値（連続値）\n",
    "    - ![img4](img4.jpg)\n",
    "- 教師あり学習は誤差を小さくする\n",
    "    - 分類では交差エントロピー誤差、回帰では平均ニ乗誤差と呼べれる誤差がよく使われる\n",
    "    \n",
    "- まとめ\n",
    "    - 教師あり学習とは、教師データをモデルに学習させる方法のこと\n",
    "    - 教師あり学習の最終目標は、テストデータを正解すること\n",
    "    - 教師あり学習は分類と回帰に分けられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06．教師なし学習のしくみ\n",
    "- 教師なし学習は「データの特長をとらえる」\n",
    "    - 教師なし学習：与えられたデータの本日的な構造や法則をアルゴリズムが自動的に抽出する機械学習アルゴリズム\n",
    "- 教師なし学習「クラスタリング」ができる\n",
    "    - ![img5](img5.jpg)\n",
    "- 教師なし学習は「次元削減」ができる\n",
    "    - 次元削減：データから重要な情報だけし抜き出し、あまり重要でない情報を削減するタスク\n",
    "    \n",
    "- まとめ\n",
    "    - 教師なし学習の最終目標は「データの特徴をとらえる」\n",
    "    - 教師なし学習は「クラスタリング」と「次元削減」ができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07．強化学習のしくみ\n",
    "- 強化学習とは\n",
    "    - 赤ちゃんが一人で立ち上がれるようになるのと同じように、正解を与えなくても試行錯誤を繰り返しながら最適な行動をするように学習する方法のこと\n",
    "    - ![img6](img6.jpg)\n",
    "- まとめ\n",
    "    - 強化学習はより多くの報酬獲得を目指す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08．統計と機械学習の違い\n",
    "- 統計と機械学習では、導く情報が違う\n",
    "    - 統計：今あるモデルを使ってうまく「データを説明する」ための分野と言い換えることができる\n",
    "    - 機械学習：「データを予測する」ことにフォーカスした分野である\n",
    "- 統計と機械悪臭の使い分け\n",
    "    - 統計：「なぜこのような推測になるのか、理由を知りたい」場合に\n",
    "    - 機械学習：「今日何が売れるか」を推測する場合\n",
    "\n",
    "- まとめ\n",
    "    - 「データを説明する」のが統計\n",
    "    - 「データを予測する」のが機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09．機械学習と特徴量\n",
    "- 機会が知能を持つこと\n",
    "    - ものごとを「分ける」ことができるようになること\n",
    "    - 特徴量：機械学習で分ける基準になる数値\n",
    "- 特徴量にまつわるボトルネック\n",
    "    - 特徴量を人間が決めることは難しいなので、ディープラーニングでアルゴリズムが自動で抽出\n",
    "- まとめ\n",
    "    - 人間が特徴量を設定するのは難しい\n",
    "    - その困難を解決できるかもしれないのがディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10．得意な分野、苦手な分野\n",
    "- 人工知能が得意な分野、苦手な分野\n",
    "    - 基準\n",
    "        - 過去にデータが存在するか\n",
    "        - データが十分にあるか\n",
    "        - データが定量的か\n",
    "        - 推論の過程がわからなくてもよいか\n",
    "- まとめ\n",
    "    - データ量や推論の用途に注目して判断する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11．機械学習の活用事例\n",
    "- 運転\n",
    "- 交通管制\n",
    "- 金融\n",
    "- 資産運用\n",
    "- マーケティング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ３章　機械学習のポロセスとコア技術"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12．機械学習の基本ワークフロー\n",
    "- 基本ワークフローと注意点\n",
    "    - 機械学習システムの開発は、通常のシステム開発と比べ、アルゴリズムの選定や機械学習の性能向上のために試行錯誤が多く、プロセス間をまたいだ手戻り（前段階に戻ってやり直すこと）が発生しやすい\n",
    "    - 各プロセスに費やす時間を適切に管理することが重要\n",
    "- ![img7](img7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13．データの収集\n",
    "- 自分でデータを記録する\n",
    "    - 十分なデータ量が確保できるか\n",
    "    - 途中で条件が変わったデータではないか\n",
    "- 官公庁やきぎょうがこうかいしているでーたをりようする\n",
    "- Web APIやスクレイピングを活用する\n",
    "    - ![img8](img8.jpg)\n",
    "- まとめ\n",
    "    - データの収集方法は、「自分で収集」「公開されているデータベースの利用」「Web APIやスクレイピングの活用」 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14．でーたの整形\n",
    "- カテゴリデータの整形\n",
    "    - ラベルエンコーディング\n",
    "    - かうんとエンコーディング\n",
    "    - One-Hotエンコーディング\n",
    "    - ![img9](img9.jpg)\n",
    "- 数値データの整形\n",
    "    - 離散化\n",
    "    - 対数変換\n",
    "    - スケーリング\n",
    "    - ![img10](img10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15．モデルの作成と学習\n",
    "- モデルとは\n",
    "    - 機械学習におけるモデルとは、入力されたデータからある出力（入力データに対する分類や予測）を出すための数理モデルのこと\n",
    "    - 「何かを入れると何かが出てくる箱」\n",
    "- 訓練誤差\n",
    "    - まず、モデルに適当なパラメータを入れて出力を計算する。すると、必ず出力データと正答データの間に見られる大きいさが訓練誤差\n",
    "- 繰り返し、学習する（イテレーション）\n",
    "    - モデルのパラメータが調整されていき、徐々に正しい予測・分類結果を出力できるように繰り返すこと\n",
    "    - ![img11](img11.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16．バッチ学習とオンライン学習\n",
    "- ★バッチ学習★\n",
    "    - すべてのデータを一括で処理する手法\n",
    "- オンライン学習\n",
    "    - 予測を切り離して学習する方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17．テストデータによる予測結果の検証\n",
    "- 汎化性能とは\n",
    "    - 未知のデータに対する予測や分類の精度のこと\n",
    "    - テストデータ：学習データを別に検証するため、残しておくデータ\n",
    "- ホールドアウト検証とk-分割交差検証（K-foldクロスバリデーション）\n",
    "    - ホールドアウト検証：データを学習用データとテスト用データにある割合でぶんわりしてけんしょうする、もっとも単純な検証方法\n",
    "    - k-分割交差検証：すべてのデータが検証データとして利用されるよう、学習データとテストデータを入れ替えて分けるなどし、複数の組み合わせを用意する\n",
    "    - Leaver-one-out交差：全データから1データずつ抜き出してテストデータとし、残りすべてを学習データとする手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18．学習結果に対する評価基準\n",
    "- 機械学習の性能評価\n",
    "    - テストデータを利用した検証結果から性能を「評価」することが必要\n",
    "- 回帰モデルのせいのうをひょうかする\n",
    "    - 予測誤差をどのように集計するかで\n",
    "- 回帰モデルにおける代表的な予測誤差集計方法\n",
    "    - ![img12](img12.jpg)\n",
    "- 分数モデルの性能を評価する\n",
    "    - ★混合行列★\n",
    "    - ![img13](img13.jpg)\n",
    "- 分数モデルにおける代表的な評価指数\n",
    "    - ![img14](img14.jpg)\n",
    "    - ![img15](img15.jpg)\n",
    "    - ![img16](img16.jpg)\n",
    "    - ![img17](img17.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19．ハイパーパラメータとモデルのチューニング\n",
    "- ハイパーパラメータ\n",
    "    - モデルを何次式にするのかといったモデルの大枠を決める数値\n",
    "- 未学習と過学習\n",
    "    - ★過学習(overfitting)★：100%の正確度が出るけど他のデータが入ると正確度がすごく低くなる\n",
    "    - 未学習(underfitting)\n",
    "- ハイパーパラメータのオートチューニング\n",
    "    - グリッドサーチ：すべてのハイパーパラメータ候補の組み合わせを試行し、もっとも性能のよいものを選択するという方法    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20．能動学習\n",
    "- ラベル付きデータの作成は煩雑\n",
    "    - 能動学習：教師データをやみくもに作って学習するのではなく、教師データの数を絞って学習する\n",
    "- ラベルを選ぶ基準\n",
    "    - まぎらしいデータのラベルを作成する\n",
    "- ラベル付きデータの作り方\n",
    "    - ![img18](img18.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21．相関と因果\n",
    "- 相関関係と因果関係\n",
    "- 疑似相関\n",
    "    - 本当は因果関係がない要素の間に、見えない外部の要因の影響で因果関係ができているように見えること\n",
    "- 疑似相関に騙されない因果分析の方法\n",
    "    - ランダム化比較試験\n",
    "    - 回帰分離デザイン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22．フィードバックループ\n",
    "- 機械学習を使ったシステムの落とし穴\n",
    "    - コードの書き方だけではシステムの振る舞いが規定できない点\n",
    "- フィードバックループ\n",
    "    - システムの振る舞いが環境を及ぼし、次に観測するデータが環境から影響を受けて変化してしまう現象\n",
    "- 隠れたフィードバックループ\n",
    "    - 直接的なフィードバックループより厄介なのか、目に見えない間接的なフィードバックループ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ★気になるワード★"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ①エキスパートシステム(expert system)\n",
    "専門家が持つ専門知識と経験、ノウハウなどをコンピュータに蓄積し、専門家と同じかそれ以上の問題解決能力を持てるように作られたシステムつまり専門的な知識を体系的に適用する人間の思考をまねるようになるということ<br>\n",
    "![img19](img19.jpg)\n",
    "<br>\n",
    "最初は大いに期待された。 しかし、ほとんどif-else 文だけで構成されたシステムにすぎず、考慮できなかった場合の数に対しては効果がなかった。すなわち、外観上に見えるのは人工知能だが、実際には精巧なプログラムと言える。<br>\n",
    "それでもいくつかの分野では人間より良い成果を見せた。<br>\n",
    "<br>\n",
    "MYCIN<br>\n",
    "-最初の専門家システムの1つ<br>\n",
    "-重症感染症を引き起こす可能性のある様々なバクテリアを識別でき、体重によって薬物をおすすめします。<br>\n",
    "<br>\n",
    "DENDRAL<br>\n",
    "-化学分析に使用される人工知能ベースの専門家システム<br>\n",
    "-物質の分光データを使用して分子構造予測<br>\n",
    "<br>\n",
    "R1 / XCON<br>\n",
    "-ユーザーが希望するコンピュータシステムを作成するため、特定のソフトウェアを選択可能<br>\n",
    "<br>\n",
    "PXDES<br>\n",
    "-データを基に患者の肺がんのタイプと程度を簡単に決定<br>\n",
    "<br>\n",
    "CaDet<br>\n",
    "-患者の初期段階で癌を識別できる臨床支援システム<br>\n",
    "<br>\n",
    "DXplain<br>\n",
    "-医師の発見によって様々な病気を示唆できる臨床支援システム<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ➁ファジィ理論(Fuzzy Logic)\n",
    "人間は曖昧な言語規則を使って単純でスピーディーに伝達することができる能力を持っている。<br>\n",
    "私は背が高いです。 辛くしてください すぐ終わりますなどなど<br>\n",
    "ファジィ論理はこうした人間の曖昧な言葉をコンピューターに聞き分けるためのものだ。<br>\n",
    "<br>\n",
    "ファジィのプロセスはファジィ化、ファジィ推論、非ファジィ化に分けられる。<br>\n",
    "<br>\n",
    "ファジィ化<br>\n",
    "![img20](img20.jpg)<br>\n",
    "どの集合にどの程度属しているか<br>\n",
    "<br>\n",
    "ファジィ推論<br>\n",
    "![img21](img21.jpg)<br>\n",
    "人間は物事を見積もって判別する際に7つを超えないことを利用した真理表をもとにファジィ結果を推論する<br>\n",
    "<br>\n",
    "非ファジィ化<br>\n",
    "上記の結果を数値に変換させる過程である。<br>\n",
    "https://m.blog.naver.com/PostView.nhn?blogId=jerrypoiu&logNo=221178162267&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "https://happy8earth.tistory.com/501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ➂バッチ学習(Batch learning)\n",
    "バッチではシステムが漸進的に学習できない。 可用なデータをすべて使用して訓練させなければならない。<br>\n",
    "このような方法はオフラインで時間と資源をたくさん使い方であろう<br>\n",
    "<br>\n",
    "まずシステムを訓練して製品システムに適用すると、それ以上の学習なしで実行可能。<br>\n",
    "<br>\n",
    "つまり学習したことを適用するだけである。\n",
    "<br>\n",
    "バッチが新しいデータについて学習するには、全体のデータを使用してシステムの新しいバージョンを一から再び訓練し、その後、以前のシステムを中止して新しいシステムに変える。 <br>\n",
    "このような方式は簡単でうまく作動するが、全体のデータセットを使って訓練するのに多くの時間を要することがある。<br>\n",
    "また、全体のデータセットを使って訓練するため、システム資源を多く消耗する。 資源が限られたシステムが自ら学習しなければならない時、大量の訓練データを運び、学習のために資源を使用する場合、問題を発生させることができる。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ④混合行列(confusion matrix)\n",
    "モデルの性能を評価する際に用いられる指標。<br>\n",
    "まず、モデルの性能を評価するために混合行列とともに必要な4つの概念がある<br>\n",
    "TP (True Positive) - 正しいものを正しく正しいと予測したもの(正解)<br>\n",
    "TN (True Negative) - でないものを正しく間違えると予測したもの(正解)<br>\n",
    "FP (False Positive) - 正しくないものを正しくないと予測したもの<br>\n",
    "FN (False Negative) - 合っているものを正しくないと予測したもの<br>\n",
    "\n",
    "![img22](img22.jpg)\n",
    "\n",
    "Precision<br>\n",
    "TP / (TP + FP)<br>\n",
    "1と予測したものの中で実際の値が1のもの ー> 私が解いた問題の中に当てた正解数<br>\n",
    "<br>\n",
    "Recakk(=sensitivity)<br>\n",
    "TP / (TP + FN)<br>\n",
    "実際の値が1の中で1だと予測したもの --> 全体の中で私がいくつ当てたか<br>\n",
    "<br>\n",
    "Accuracy<br>\n",
    "(TP + TN) / (TP + TN + FP + FN)<br>\n",
    "全体の場合の数のうちTRUEのもの<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⑤過学習(overfitting)\n",
    "マシンラーニング(machine learning)においてoverfittingは学習データを過度によく学習することを意味する。 一般に学習データは実データの部分集合の場合がほとんどである。 したがって、以下のグラフのように学習データについては誤差が減少するが、実際のデータについては誤差が増加する地点が存在し得る。<br>\n",
    "\n",
    "![img23](img23.jpg)\n",
    "<br>\n",
    "Overfitting をこのような観点から見ると、overfitting は学習データに対して過度に学習し、実際のデータに対する誤差が増加する現象である。<br>\n",
    "例えば、黄色の猫を見て猫の特性を学習した人が黒や白の猫を見てはそれを猫と認識できない現象がoverfittingと似ている場合である。<br>\n",
    "<br>\n",
    "解決方法<br>\n",
    "<br>\n",
    "1.データ量を増やす<br>\n",
    "2.モデルの複雑さを減らす<br>\n",
    "人工神経網の複雑度は秘匿層(hidden layer)の数や媒介変数の数などで決定<br>\n",
    "3.ドロップアウト（Dropout）<br>\n",
    "ドロップアウトは学習過程でネットワークの一部を使用しない方法<br>\n",
    "ドロップアウトの割合を0.5にすると、学習過程ごとにランダムに半分のニューロンを使用せず、半分のニューロンだけを使用<br>\n",
    "ニューラルネットワーク学習時にのみ使用し，予測時には使用しないのが一般的<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
