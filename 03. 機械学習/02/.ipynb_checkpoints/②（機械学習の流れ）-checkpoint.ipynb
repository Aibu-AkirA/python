{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "ry-G_A7Wxbf",
    "id": "chapter_name"
   },
   "source": [
    "#  Chapter2 機械学習の流れ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 機械学習の流れ（P.26）  \n",
    "* 教師あり学習で行うことの流れ  \n",
    "\n",
    "    1. データ収集\n",
    "    1. データクレンジング（データの精度を高める） \n",
    "    1. 機械学習手法でデータを学習\n",
    "    1. テストデータで性能をテスト\n",
    "    1. 機械学習モデルをWebなどに実装\n",
    "\n",
    "\n",
    "* **機械学習を行うといっても事前の準備や結果の考察が必要**\n",
    "    * 多くの場合データ収集・データクレンジングに時間がかかる\n",
    "\n",
    "\n",
    "* データの学習  \n",
    "    * 「Iris（あやめ）」\n",
    "        * 機械学習でよく使われるサンプルデータセット\n",
    "            * [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)からダウンロード可能\n",
    "                * \n",
    "            * がく片（sepal）と花びら（petal）の長さと花弁とその品種\n",
    "    * 品種（setosa, versicolor）を分類する\n",
    "        * 適当に線を引く（分類する）\n",
    "        * その線が妥当な位置にあるかを計算で求める\n",
    "        * 線の位置を改善するほうに修正する\n",
    "        * 適切に点を分類できる位置に線を引けたら終了\n",
    "    * モデル\n",
    "        * 学習の結果、コンピュータ自身が自分で答えを見つけ、データのパターンから作られた基準"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 学習データの使い方（P.30）\n",
    "* 「教師あり学習」…扱うデータを「トレーニングデータ」と「テストデータ」に分けて用いる\n",
    "    * 機械学習は「未知のデータを予測する」ことが目的\n",
    "    * モデル評価には、学習には使われていないデータ（テストデータ）を用いる\n",
    "        * 「MNIST」では60,000枚がトレーニングデータ、10,000枚がテストデータ\n",
    "        * 多くの場合は全体の20%ほどをテストデータに用いる\n",
    "* データ分割方法  \n",
    "    * ホールドアウト法\n",
    "    * k-分割交差検証（k-クロスバリデーション）法\n",
    "    \n",
    "\n",
    "* ホールドアウト法\n",
    "    * scikit-learnに用意された関数train_test_split()が使える\n",
    "        * [**`train_test_split(*arrays, **options)`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)  \n",
    "        * test_size=XXXで、データ全体からテストデータとして選びたい割合を0～1までの数値で指定\n",
    "        * random_state=0は実験の再現性を担保するために指定\n",
    "\n",
    "\n",
    "* k-分割交差検証（k-クロスバリデーション）\n",
    "    * 非復元抽出を用いて、トレーニングデータセットをk分割し、そのうちのk-1個のデータを学習データセットとして用い、  \n",
    "    残りの1個をモデルのテストに用いる手法\n",
    "    * 結果として、k個のモデルとそのモデルに対する性能評価がk個得られる  \n",
    "        * k個の性能評価の平均をとり、平均性能を算出する\n",
    "        * より安定した正確なモデル評価ができる\n",
    "        * ホールドアウト法よりもk倍の演算が必要\n",
    "    * 一般的に用いられるkの値は5～10\n",
    "        * データセットが大きい場合はkの値を増やすことでよい結果が得られる場合が多い\n",
    "        * データセットがかなり小さい場合、一個抜き（Leave-One-Out:LOO）交差検証が推奨\n",
    "            * 例えばデータセットが50～100行以下\n",
    "    * scikit-learnに用意された関数model_selection.cross_val_score()が使える\n",
    "        * [**`model_selection.cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=’warn’, n_jobs=None, verbose=0, fit_params=None, pre_dispatch=‘2*n_jobs’, error_score=’raise-deprecating’)`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "        * バージョン0.20以降、cross_validationモジュールからmodel_selectionモジュールに移動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### リスト 2.1（P.33）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (120, 4)\n",
      "y_train : (120,)\n",
      "X_test : (30, 4)\n",
      "y_test : (30,)\n"
     ]
    }
   ],
   "source": [
    "# コードの実行に必要なモジュールを読み込みます\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Irisというデータセットを読み込みます\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 「X_train, X_test, y_train, y_test」にデータを格納します\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# トレーニングデータとテストデータのサイズを確認します\n",
    "print (\"X_train :\", X_train.shape)\n",
    "print (\"y_train :\", y_train.shape)\n",
    "print (\"X_test :\", X_test.shape)\n",
    "print (\"y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### リスト 2.3（P.37）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86666667 0.96666667 0.83333333 0.96666667 0.93333333]\n",
      "平均スコア : 0.9133333333333334\n"
     ]
    }
   ],
   "source": [
    "# コードの実行に必要なモジュールを読み込みます\n",
    "##from sklearn import svm, datasets, cross_validation\n",
    "from sklearn import svm, datasets, model_selection\n",
    "\n",
    "# 「Iris」というデータセットを読み込みます\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 機械学習アルゴリズムSVMを使用します\n",
    "svc = svm.SVC(C=1, kernel=\"rbf\", gamma=0.001)\n",
    "\n",
    "# 交差検証法を用いてスコアを求めます\n",
    "# 内部では、X、yがそれぞれ「X_train, X_test, y_train, y_test」の様に分割され処理されます\n",
    "scores = model_selection.cross_val_score(svc, X, y, cv=5)\n",
    "\n",
    "# トレーニングデータとテストデータのサイズを確認します\n",
    "print (scores)\n",
    "print (\"平均スコア :\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 過学習（P.38）\n",
    "* 過学習（オーバーフィッティング）\n",
    "    * コンピュータが学習しすぎてしまい、正しい基準が構築されないこと\n",
    "    * 過学習を起こしているモデル：バリアンスが高い\n",
    "* 過学習の回避  \n",
    "    * 深層学習（ディープラーニング）の場合、「Dropout（ドロップアウト）」という手法を用いる\n",
    "        * 学習時にランダムに一部のニューロンを消し去る\n",
    "    * 正則化\n",
    "        * 偏りがあるデータの影響をなくす（消す）方法\n",
    "* 学習不足\n",
    "    * コンピュータがデータを学習できていない状態\n",
    "    * 学習不足を起こしているモデル：バイアスが高い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 アンサンブル学習（P.41）  \n",
    "* アンサンブル学習\n",
    "    * 複数のモデルに学習させることにより、データの一般化を獲得しようとする試み\n",
    "        * バギング\n",
    "            * 複数のモデルを同時に学習させ、予測結果の平均をとることで予測結果の汎化を試みる\n",
    "        * ブースティング\n",
    "            * モデルの予測結果に対するモデルを作成し、汎化性能を高める手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ほげ要望\n",
    "第２章の添削問題をやってくれたら工藤が喜びます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# エクストラほげ問題②\n",
    "## Pythonで学ぶ線形代数\n",
    "## ベクトルの大きさと単位ベクトル\n",
    "大学に進学をした理系学生が１年生の最初に習うのが線形代数です。その知識を使い今習っているPythonの技術向上を目指しましょう。   \n",
    "※ヒントのようなもの  \n",
    "①https://oguemon.com/topic/study/linear-algebra/  \n",
    "②https://mathtrain.jp/category/senkei  \n",
    "③https://python.atelierkobato.com/linear/  \n",
    "④https://examist.jp/category/mathematics/  \n",
    "⑤http://www.geisya.or.jp/~mwm48961/koukou/index_m.htm  \n",
    "  \n",
    "# もんだいだよん(^ω^)\n",
    "## ベクトルの大きさ\n",
    "### ①ユークリッドノルム\n",
    "PythonのライブラリNumPyを用いて解きなさい  \n",
    "ベクトル$\\vec{a}$のユークリッドノルムを求めなさい\n",
    "  \n",
    "$\n",
    "  \\vec{a} = \\left(\n",
    "    \\begin{array}{ccc}\n",
    "      1 \\\\\n",
    "      2 \\\\\n",
    "    \\end{array}\n",
    "  \\right)\n",
    "$\n",
    "### ②scipy.linalg.norm()\n",
    "PythonのライブラリNumPyを用いて解きなさい  \n",
    "ベクトル$\\vec{a}$のユークリッドノルムをscipy.linalg.norm()を用いて求めなさい\n",
    "  \n",
    "$\n",
    "  \\vec{a} = \\left(\n",
    "    \\begin{array}{ccc}\n",
    "      1 \\\\\n",
    "      2 \\\\\n",
    "    \\end{array}\n",
    "  \\right)\n",
    "$\n",
    "## 単位ベクトル\n",
    "### ③単位ベクトル\n",
    "PythonのライブラリNumPyを用いて解きなさい  \n",
    "ベクトル$\\vec{a}$の単位ベクトルを求めなさい\n",
    "  \n",
    "$\n",
    "  \\vec{a} = \\left(\n",
    "    \\begin{array}{ccc}\n",
    "      1 \\\\\n",
    "      2 \\\\\n",
    "    \\end{array}\n",
    "  \\right)\n",
    "$\n",
    "# ヒントのようなもの\n",
    "以下の流れでプログラムしたらいいと思います  \n",
    "\n",
    "``` python\n",
    "#ライブラリのインポート\n",
    "\n",
    "#ベクトルやスカラー定義\n",
    "\n",
    "#計算処理\n",
    "\n",
    "#結果のプリント\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
