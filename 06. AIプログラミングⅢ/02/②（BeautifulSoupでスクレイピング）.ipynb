{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ②（BeautifulSoupでスクレイピング）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoupでスクレイピング\n",
    "### BeautifulSoupのインストール\n",
    "#### コマンド\n",
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoupの基本的使い方\n",
    "#### 実行結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = スクレイピングとは？\n",
      "p  = Webページを解析すること。\n",
      "p  = 任意の箇所を抽出すること。\n"
     ]
    }
   ],
   "source": [
    "# ライブラリを取り込む --- (※1)\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# 解析したいHTML --- (※2)\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1>スクレイピングとは？</h1>\n",
    "  <p>Webページを解析すること。</p>\n",
    "  <p>任意の箇所を抽出すること。</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※3)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 任意の部分を抽出する --- (※4)\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "# 要素のテキストを表示する --- (※5)\n",
    "print(\"h1 = \" + h1.string)\n",
    "print(\"p  = \" + p1.string)\n",
    "print(\"p  = \" + p2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任意のidで要素を探す方法\n",
    "#### 実行結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title=スクレイピングとは？\n",
      "#body=Webページから任意のデータを抽出すること\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1 id=\"title\">スクレイピングとは？</h1>\n",
    "  <p id=\"body\">Webページから任意のデータを抽出すること</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※1)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find()メソッドで取り出す --- (※2)\n",
    "title = soup.find(id=\"title\")\n",
    "body  = soup.find(id=\"body\")\n",
    "\n",
    "# テキスト部分を表示 \n",
    "print(\"#title=\" + title.string)\n",
    "print(\"#body=\"  + body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複数の要素を取得する find_all()メソッド\n",
    "#### 実行結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uta > http://uta.pw\n",
      "oto > http://oto.chu.jp\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://uta.pw\">uta</a></li>\n",
    "    <li><a href=\"http://oto.chu.jp\">oto</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※1)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# findAll()メソッドで取り出す --- (※2)\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# リンク一覧を表示 --- (※3)\n",
    "for a in links:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text, \">\", href) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urlopen()とBeautifulSoupの組み合わせ\n",
    "#### 実行結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京都 渋谷区 宇田川町\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"https://api.aoikujira.com/zip/xml/1500042\"\n",
    "\n",
    "# urlopen()でデータを取得 --- (※1)\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoupで解析 --- (※2)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 任意のデータを抽出 --- (※3)\n",
    "ken = soup.find(\"ken\").string\n",
    "shi = soup.find(\"shi\").string\n",
    "cho = soup.find(\"cho\").string\n",
    "print(ken, shi, cho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSSセレクターを使う\n",
    "#### 実行結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = トルストイの名言\n",
      "li = 汝の心に教えよ、心に学ぶな\n",
      "li = 謙虚な人は誰からも好かれる。\n",
      "li = 強い人々は、いつも気取らない。\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# 解析対象となるHTML --- (※1)\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>トルストイの名言</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>汝の心に教えよ、心に学ぶな</li>\n",
    "    <li>謙虚な人は誰からも好かれる。</li>\n",
    "    <li>強い人々は、いつも気取らない。</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※2)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 必要な部分をCSSクエリで取り出す\n",
    "# | タイトル部分を取得 --- (※3)\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(\"h1 =\", h1)\n",
    "\n",
    "# | リスト部分を取得 --- (※4)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")\n",
    "for li in li_list:\n",
    "\tprint(\"li =\", li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo!ファイナンスの為替情報の取得\n",
    "#### 実行結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/jpy= 106.930000\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# HTMLを取得\n",
    "url = \"https://stocks.finance.yahoo.co.jp/stocks/detail/?code=usdjpy\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTMLを解析\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 任意のデータを抽出 --- (※1)\n",
    "price = soup.select_one(\".stoksPrice\").string\n",
    "print(\"usd/jpy=\", price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
