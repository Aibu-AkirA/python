{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIプログラミングIII　試験問題・解答用紙\n",
    "\n",
    "### 注意事項\n",
    "* ノートブック名（画面の上部に表示されている）を編集し、\"氏名\"を自分の名前に変えること\n",
    "* 解答は実行結果も表示された状態でHTML出力すること  \n",
    "* プログラムの実行結果として出力されるファイルも提出すること\n",
    "    * exam1.png, exam6.png, exam8.py, exam8.json, exam11.xlsx, exam12.json \n",
    "* SNS、Yahoo!知恵袋等のQAサービスは利用しないこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "吉田学園情報ビジネス専門学校HP（ https://yoshida-jobi.jp/ ）のトップページ下部に表示されているロゴ画像（下図参照）をダウンロードして「exam1.png」として保存するプログラムを完成させなさい。  \n",
    "ただし、画像の保存にはurllib.request.urlretrieve()関数を使用すること。  \n",
    "ロゴ画像のURLは実際のページを表示して確認すること。  \n",
    "\n",
    "<img src=\".\\fig\\fig_1.png\" width=\"700\" alt=\"情ビロゴ画像\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存しました\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# URLと保存パスを指定\n",
    "url = \"https://yoshida-jobi.jp/wp-jobi/wp-content/themes/jobi/images/dist/common/logo/header_logo_black.svg\"\n",
    "savename =\"exam1.svg\"\n",
    "\n",
    "# ダウンロードとファイル保存（urllib.request.urlretrieve()関数を使用する）\n",
    "\n",
    "\n",
    "urllib.request.urlretrieve(url, savename)\n",
    "print(\"保存しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"exam1.svg\" width=\"700\" alt=\"情ビロゴ画像\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "以下の処理を行うプログラムを完成させなさい。  \n",
    "* 「クジラWeb API」で公開されている「クジラ 百人一首 API」を利用して、以下に示す条件で百人一首を検索し出力する\n",
    "    * 「クジラ百人一首API」のURL： https://api.aoikujira.com/hyakunin/get.php\n",
    "    * URLアクセス時のパラメータ\n",
    "        * fmt：\"XML\"を指定する\n",
    "        * key：\"ちはや\"を指定する\n",
    "* パラメータは変数valuesに設定し、URLエンコードしてURLに付加すること\n",
    "* 検索結果はXMLデータで返されるので、BeautifulSoupで解析し、漢字の上の句・下の句をprint()関数で出力する\n",
    "* XMLデータの定義はAPI紹介ページ（ https://api.aoikujira.com/index.php?hyakunin&show ）の「検索の例」を参照すること  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<kami>ちはやぶる 神代もきかず 竜田川</kami> <simo>からくれなゐに 水くくるとは</simo>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "# 「クジラ百人一首API」のURLを設定する\n",
    "api = \"https://api.aoikujira.com/hyakunin/get.php\"\n",
    "\n",
    "# アクセス時のパラメータをvaluesに設定する\n",
    "values = {\n",
    "    \"fmy\" : \"XML\",\n",
    "    \"key\" : \"ちはや\"\n",
    "}\n",
    "\n",
    "# パラメータをURLエンコードする\n",
    "params = urllib.parse.urlencode(values)\n",
    "\n",
    "# 「クジラ百人一首API」のURLにURLエンコードしたパラメータを付加する\n",
    "url = api + \"?\" + params\n",
    "\n",
    "# ページを開きデータを取得\n",
    "res = urllib.request.urlopen(url).read()\n",
    "\n",
    "# BeautifulSoupで解析\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 漢字の上の句、下の句情報を抽出\n",
    "kami = soup.items.kami\n",
    "shimo = soup.items.simo\n",
    "\n",
    "# 出力\n",
    "print(kami, shimo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "変数htmlに格納されているHTML情報から、h1タグ、liタグの各要素を取得し、テキスト部分を出力するプログラムを完成させなさい。  \n",
    "なお、要素へのアクセスには、ルート要素からドット（.）を使ってアクセスする方法を利用すること  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 聖書\n",
      "li = 創世記\n",
      "li  = 出エジプト記\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# 解析したいHTML\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<h1>聖書</h1>\n",
    "<ol>\n",
    "  <li>創世記</li>\n",
    "  <li>出エジプト記</li>\n",
    "</ol>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "# 要素を抽出する\n",
    "h1 = soup.html.body.h1\n",
    "li1 = soup.html.body.ol.li\n",
    "li2 = li1.next_sibling.next_sibling\n",
    "\n",
    "# 要素のテキストを表示する\n",
    "print(\"h1 = \" + h1.string)\n",
    "print(\"li = \" + li1.string)\n",
    "print(\"li  = \" + li2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "「kujira.html」を読み込み、下図に示した要素を抽出して「（テキスト情報） > （リンクURL）」の形式で出力するプログラムを完成させなさい。  \n",
    "なお、抽出に使用する要素名はファイルをブラウザで開き確認すること。 \n",
    "\n",
    "<img src=\".\\fig\\fig_4.png\" width=\"600\" alt=\"クジラWeb API画像2\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "時間API > http://api.aoikujira.com/index.php?time&show\n",
      "郵便番号API > http://api.aoikujira.com/index.php?zip&show\n",
      "IP確認API > http://api.aoikujira.com/index.php?ip&show\n",
      "百人一首API > http://api.aoikujira.com/index.php?hyakunin&show\n",
      "日本語プログラミング言語「なでしこ」更新情報RSS > http://nadesi.com/History.xml\n",
      "英単語頻出2000語 > http://api.aoikujira.com/index.php?eitango2000&show\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# ファイルを開く\n",
    "\n",
    "fp = open(\".\\kujira.html\",'r', encoding=\"utf8\")\n",
    "\n",
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(fp, \"html.parser\")\n",
    "\n",
    "# 要素の抽出\n",
    "li_list = soup.select(\"ol.list2 > li \")\n",
    "\n",
    "# リンク部分の情報を表示\n",
    "for li in li_list:\n",
    "    a = li.a\n",
    "    name = a.string\n",
    "    href = a.attrs[\"href\"]\n",
    "    print(name, \">\", href)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "変数htmlに格納されているHTML情報のうち、正規表現を利用して以下の条件に合致するURLを抽出するプログラムを完成させなさい。\n",
    "* `\"http://\"`ではじまるURL\n",
    "* `\".htm\"`で終わるURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== http://～～～ ===\n",
      "https://example.com/fuga.html\n",
      "https://example.com/foo.htm\n",
      "https://example.com/test.jpg\n",
      "=== ～～～.htm ===\n",
      "hoge.htm\n",
      "https://example.com/foo.htm\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "# 解析したいHTML\n",
    "html = \"\"\"\n",
    "<ul>\n",
    "  <li><a href=\"hoge.htm\">hoge</li>\n",
    "  <li><a href=\"https://example.com/fuga.html\">fuga*</li>\n",
    "  <li><a href=\"https://example.com/foo.htm\">foo*</li>\n",
    "  <li><a href=\"https://example.com/test.jpg\">foo*</li>\n",
    "  <li><a href=\"http://example.com/aaa.png\">aaa</li>\n",
    "  <li><a href=\"http://example.com/bbb.html\">aaa</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "# BeautifulSoupで解析\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 正規表現でhrefからhttp://～～～を抽出\n",
    "li = soup.find_all(href=re.compile(r\"^https://\"))\n",
    "\n",
    "# 抽出した要素のhref属性を出力\n",
    "print(\"=== http://～～～ ===\")\n",
    "for e in li:\n",
    "    print(e.attrs['href'])\n",
    "    \n",
    "# 正規表現でhrefから～～～.htmを抽出\n",
    "li = soup.find_all(href=re.compile(r\"htm$\"))\n",
    "\n",
    "# 抽出した要素のhref属性を出力\n",
    "print(\"=== ～～～.htm ===\")\n",
    "for e in li:\n",
    "    print(e.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "seleniumライブラリを利用して、以下の処理を行うプログラムを完成させなさい。  \n",
    "* yahoo( https://www.yahoo.co.jp/ )にアクセスする\n",
    "* 検索窓に\"吉田学園情報ビジネス専門学校\"と入力し、検索を実行する\n",
    "    * 検索文字を入力するテキストボックス、submitを行うフォームはfind_element_by_name()関数で取得する\n",
    "    * テキストボックス、フォームのname属性はブラウザでサイトにアクセスし管理者ツールで確認する\n",
    "* 検索結果の表示画面のスクリーンショットを取得し、「exam6.png」として保存する\n",
    "* 検索結果HTMLをBeautifulSoupで解析し、URL情報を出力する\n",
    "    * URL情報の抽出はCSSセレクターを利用し\".sw-Card.Algo\"要素のhref属性を取得することで可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アクセスしました\n",
      "検索ワードを入力して検索ボタンをクリックしました\n",
      "https://rd.listing.yahoo.co.jp/o/search/GU=ppefH8NxDuNciaagzvGjton2PMvadcjqTF77dz4X8gnMJEYLBdLJfmL0LBBCIqfBsioNdLAW4cMm4IKxfhXzEmMQY1esn1whlXjfobUr4Sj6avojmeGoywQ2fL54GWrAxkTY8.GWeZQHosInYf.LWvgyRVEBS_MNE.vYdcgq_eNzlHY-;/?ep=dV3kfopwHqqwQrmjhhcYqjr3VrBHsxKCCWHTYjhUD2oNO1fP6Wt5Ilkg.auHUjo4an0DfCIz_oAZVj4wcaQNdgK0NhEVE.sTcsxXa_QdzSr08Xi3a_lZeLbFzsBK_bi3&v=1\n",
      "https://rd.listing.yahoo.co.jp/o/search/GU=ozbZAIZxDuOPMsmEObCAKrM1s7UyffFtOSQe1s4W9vyL.ly9tixCrKhdrHbHdM7hYK_veXZLRoFLkHr..mgg2eH7xch_.IoXirH9JC.uEenEZ9UmU50vVcn16soMpk.JhJcrW2ggESSAhqyiZADzJ4bTH0ATzwLlytoeXu4ubL4ACwE-;/?ep=zCkxQpZwHqrxPyVmlLPywFNWI.rhsANGR8EIHapaR.TcG5MiycfMIDTHLELKtWTgHU4o25OvUAbnFU6.MRIlCMD1txJyMpZYkzsLZjY0x_hyWyKdrqwvbHlxQJg5brWmD1o-&v=1\n",
      "https://rd.listing.yahoo.co.jp/o/search/GU=OwSMvVlxDuOPo31Ef.gVmqfRXrETgh68OefURRY6taFrghZhqCKfzsEFtBEwtvsTaYsb7yYSi9JEiSJc1UBFfs2iiygQ6EiBvAUmoovhSo0iRs9lxKukZtTgFbU2K3ANqn0KaEg0j_Dh41WZmD9ijm7AFi1NlHr0A8x4ULzVQID32RY-;/?ep=OYxpQ3FwHqrr4UDB7wAyaIdfx1gE_EvsrjTon.4WrLJAPOlouAB4.l0bFhAP84QAINC0n1Vxj1EEBBpEOhjVJbt1cFUlTsiVCfyCAiKP1th8qW19ktub2Mni4yjSrg1GUcc-&v=1\n",
      "https://rd.listing.yahoo.co.jp/o/search/GU=3S8wsi5xDuOmyMUMFbRG1tWorVybjne6cmNIl2Twqfz9XtSDbzFRl1iTB1wAh29pnuvO7krsFVno.ENvdfG0My6bbwrwOG0tVMZ8QGMxsTASPqTaF3qINC1703BH5q.0lFiRE4TjoEA7gBr2eus24NpbLI4cgFSu25SeLgbVcQnfTGQ-;/?ep=8d.KI1JwHqqA_hEdKUT0OqJwnZVNiM3n6OiX1oF0upHimSpK9tDBdgVJ5ljWRKChts7mIl67odUCdAKtI.1HI1EDgW.Xj2OUekTQ_xkL8_12jgKCyL_LyD_O_shWYOeTeaA-&v=1\n",
      "https://yoshida-jobi.jp/\n",
      "https://twitter.com/yoshida_jobi?lang=ja\n",
      "https://yoshida-entry.jp/?sid=5\n",
      "https://school.js88.com/scl_sen/14/scldetail\n",
      "https://yoshida-g.ac.jp/disclosure/jobi/syllabus-jobi/\n",
      "https://map.yahoo.co.jp/maps?ei=UTF-8&type=scroll&mode=map&lon=141.3618132&lat=43.0803545&p=%E5%90%89%E7%94%B0%E5%AD%A6%E5%9C%92%E6%83%85%E5%A0%B1%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E5%B0%82%E9%96%80%E5%AD%A6%E6%A0%A1&z=16&gid=VHY1_xcHle-&uid=af3469c352969482d15eb222f8b5552a2e4acaf2&fa=ids\n",
      "https://shingakunet.com/gakko/SC001644/\n",
      "https://www.minkou.jp/vcollege/school/review/20843/\n",
      "https://rd.listing.yahoo.co.jp/o/search/GU=bIfhSXNxDuNvHBqhdBu9hjcduVpnUkUHb5r9b7zuv_XzR6kBmSLuXtXDIEQqiJtqCe2BUxHdMkCb.Kt.bQInzEkixuxkgg2Isj3T_UKNjTfDLRTsjVi2Nk7hL4e3A8b_IZpuHfEZJQfmMloB3ZweFS0UQBd3w_MTdTSEGp67L0YaT8KiOB2TbA--;/?ep=YwT1ifdwHqprrehWNWSwgD1T5RdY3y8Tmrf9NKyUcekqDB_zk8G6MrhpwPCEkc920Nk.Ls8Yq2Kxg59f63oQbui39E7pXWA4rUkqb.kJOF25D6RMFaagDVpf1EaM0NySiQ--&v=1\n",
      "https://rd.listing.yahoo.co.jp/o/search/GU=e9oWG4JxDuM88DXq1bI3POdehl._wpLD0YCRSUL5NBJfsEW5o12_Bejy6Z8iBXixfUfYad.IM3eyU7BD8wFc7sIJXMO5W5kPuK2vV2EjOTUzZSWOznjKMa07rMIrss1rv39iOKZ0ai55_DRoIH7T4DBc_VmsoxiTMdtr.ddsASdfBA6LknE27g--;/?ep=xPWK4uJwHqqBtCjvd3rdXKB1uPFQuXz4rMxtePT9.h6Z05t5Rrv0y.267n2b73euTnQQI8XW_RwjLNv13799FqRKclw4nnx8MsObMPUFnKp52ciCe7BBZqnFiZUs8Nvv3_s-&v=1\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import chromedriver_binary\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Chrome起動用オプションを生成\n",
    "options = Options()\n",
    "\n",
    "# Chromeを起動\n",
    "browser = webdriver.Chrome(executable_path='chromedriver', options=options)\n",
    "\n",
    "# yahooトップページのURLを指定\n",
    "url = \"https://www.yahoo.co.jp/\"\n",
    "\n",
    "# Chromeでアクセス\n",
    "browser.get(url=url)\n",
    "\n",
    "print(\"アクセスしました\")\n",
    "\n",
    "# 検索窓テキストボックス要素を取得\n",
    "e = browser.find_element_by_name('p')\n",
    "\n",
    "# 入力内容をクリア\n",
    "e.clear()\n",
    "\n",
    "# 検索文字列を入力\n",
    "e.send_keys(\"吉田学園情報ビジネス専門学校\")\n",
    "\n",
    "# フォーム要素を取得\n",
    "frm = browser.find_element_by_class_name(\"_63Ie6douiF2dG_ihlFTen.rapid-noclick-resp\")\n",
    "\n",
    "# フォームを送信\n",
    "frm.click()\n",
    "\n",
    "print(\"検索ワードを入力して検索ボタンをクリックしました\")\n",
    "\n",
    "# ページのロード完了まで待機\n",
    "WebDriverWait(browser, 1000)\n",
    "\n",
    "# 画面をキャプチャしてファイルに保存\n",
    "browser.save_screenshot('exam6.png')\n",
    "\n",
    "# ページ情報を取得\n",
    "page_source = browser.page_source\n",
    "\n",
    "# BeautifulSoupによる解析\n",
    "soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "# 検索結果のURL情報をもつ要素を取得\n",
    "li_list = soup.select(\"div.sw-CardBase\")\n",
    "\n",
    "for li in li_list:\n",
    "    # aタグ情報を取得\n",
    "    a = li.a\n",
    "    \n",
    "    # href属性を取得\n",
    "    href = a.attrs[\"href\"]\n",
    "\n",
    "    # 出力\n",
    "    print(href)\n",
    "\n",
    "# ブラウザを終了\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\n",
    "OpenWeatherMapのWebAPI（ https://api.openweathermap.org/data/2.5/weather ）を利用して、下記の情報を取得・出力するプログラムを完成させなさい。  \n",
    "なお、API取得に必要なAPIキーは、授業で各自取得したキーを使用すること。  \n",
    "また、気温の単位変換（ケルビン→摂氏）、時刻の変換（unixtime→日本標準時（JST））はlambdaを使用した無名関数を定義し使用すること。\n",
    "* 天気情報を取得する都市\n",
    "    * 札幌（Sapporo-shi,JP）、東京（Tokyo,JP）\n",
    "* 出力する情報\n",
    "    * 都市名\n",
    "    * 天気\n",
    "    * 天気（詳細）\n",
    "    * 気温（摂氏、小数点以下第1位まで出力）\n",
    "    * 湿度\n",
    "    * 風速\n",
    "    * 雲量\n",
    "    * データ時刻（日本標準時（JST）で出力）\n",
    "    \n",
    "取得できる主な情報は下図の通り。\n",
    "<img src=\".\\fig\\fig_7.png\" width=\"600\" alt=\"OpenWeaterhMap\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json, pprint\n",
    "import datetime as dt\n",
    "\n",
    "# APIキーの指定 - 取得したAPI Keyを設定する\n",
    "apikey = \"882601ae27b7d15cbced62a989a97a53\"\n",
    "\n",
    "# 天気を調べたい都市の一覧\n",
    "cities = \"Sapporo-shi,JP\"\n",
    "\n",
    "# APIのひな型\n",
    "api = \"https://api.openweathermap.org/data/2.5/weather?q={city}&APPID={key}\"\n",
    "\n",
    "# 温度変換(ケルビン→摂氏)無名関数の定義\n",
    "k2c = round(lambda x : x - 273.15, 1)\n",
    "\n",
    "# 時刻変換（unixtime→JST（日本標準時間））無名関数の定義\n",
    "unix2jst = lambda x : dt.datatime.fromtimestamp(x)\n",
    "\n",
    "# 各都市の天気を取得する\n",
    "for name in cities:\n",
    "    # APIのURLを得る\n",
    "    url = \n",
    "    \n",
    "    # 実際にAPIにリクエストを送信して結果を取得する\n",
    "    r = \n",
    "    \n",
    "    # 結果はJSON形式なのでデコードする\n",
    "    data = \n",
    "    \n",
    "    # 結果を画面に表示\n",
    "    print(\"+ 都市=\", )\n",
    "    print(\"| 天気=\", )\n",
    "    print(\"| 天気=\", )\n",
    "    print(\"| 気温=\"  )\n",
    "    print(\"| 湿度=\", )\n",
    "    print(\"| 風速=\", )\n",
    "    print(\"| 雲量=\", )\n",
    "    print(\"| データ時刻=\", )\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\n",
    "Scrapyを用いて、「kujira.html」の中のURLリンク情報（テキスト情報とURL）を抽出し、「exam8.json」に保存するプログラムを完成させなさい。  \n",
    "※Jupyter Notebook上では実行できないので、PyCharm上で実行し、作成したSpiderサブクラス（exam8.py）と出力結果（exam8.json）を提出する\n",
    "* 解答の流れ\n",
    "    * 「kujira.html」をC:\\tempフォルダにコピーする\n",
    "    * PyCharmのTerminalから、「C:\\Users\\（ユーザ名）\\Desktop\\AIプログラミング3」フォルダにScrapyプロジェクト（exam8）を作成する\n",
    "    * 出力結果が文字化けしないよう、「settings.py」に必要な記述を追加する\n",
    "    * Spiderサブクラス（exam8.py）を作成し、下のソースコードを参考にしてプログラムを完成させる\n",
    "        * 下に記載のコードを参考に作成する\n",
    "    * PyCharmのTerminalから、Scrapyを実行し、出力結果をexam8.jsonに出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class exam8Spider(scrapy.Spider):\n",
    "    name = 'exam8'\n",
    "    start_urls = [\n",
    "      'file://c/temp/kujira.html'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        # URLリンク情報を抽出 \n",
    "        li_list = \n",
    "        for a in li_list:\n",
    "            # href属性とテキストを取り出す\n",
    "            href = \n",
    "            text = \n",
    "            # 結果を戻す\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\n",
    "横浜市地域防災拠点データ（ shelter.xml ）から\n",
    "* 名前（Name）\n",
    "* 所在地（Ward、Address）  \n",
    "\n",
    "を抽出して出力するプログラムを完成させなさい。  \n",
    "なお、出力は以下に示す形式とする\n",
    "\n",
    "```\n",
    "■名前： 生麦小学校\n",
    "　住所： 鶴見区生麦四丁目15番1号\n",
    "■名前： 三ツ沢小学校\n",
    "　住所： 神奈川区三ッ沢中町4番地17\n",
    "■名前： 東小学校\n",
    "　住所： 西区東ケ丘59番地\n",
    "■名前： 本町小学校\n",
    "　住所： 中区花咲町3丁目86番地\n",
    "■名前： 南吉田小学校\n",
    "　住所： 南区高根町2丁目14番地\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib.request as req\n",
    "import os.path\n",
    "\n",
    "# XMLファイル指定\n",
    "savename = \"shelter.xml\"\n",
    "\n",
    "# BeautifulSoupで解析\n",
    "xml = \n",
    "soup = \n",
    "\n",
    "# 抽出データ格納用変数\n",
    "info = []\n",
    "# XMLデータから名前と所在地を抽出する\n",
    "for i in \n",
    "    name = \n",
    "    ward = \n",
    "    addr = \n",
    "    \n",
    "\n",
    "# 防災拠点を表示\n",
    "for s in info:\n",
    "    print(\"■名前：\", )\n",
    "    print(\"　住所：\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10\n",
    "「temperature.csv」を読み込んで、「地点」列と「最高気温」列を抽出して出力するプログラムを完成させなさい。  \n",
    "なお、CSVファイルの項目は、「temperature.csv」をエディタ、またはExcelで開いて確認すること。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, codecs\n",
    "\n",
    "filename = \"temperature.csv\"\n",
    "# CSVファイルを開く\n",
    "fp = \n",
    "\n",
    "# 一行ずつ読みこみ、「地点」「最高気温」を出力する\n",
    "reader = \n",
    "for cells in reader:\n",
    "    print(               )\n",
    "\n",
    "# ファイルのクローズ    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11\n",
    "「temperature.xlsx」を読み込んで、以下の処理を行うプログラムを完成させなさい。  \n",
    "なお、Excelファイルの項目は、「temperature.xlsx」をExcelで開いて確認すること。  \n",
    "* 「temperature.xlsx」に以下の情報を追記した「exam11.xlsx」を作成し保存する\n",
    "    * F1セルに\"最高の最高気温\"と追記\n",
    "    * G1セルにデータの中で最高の気温を記録した地点名を追記\n",
    "    * H1セルにデータの中で最高の気温を記録した地点の気温を赤色の文字で追記\n",
    "    * F2セルに\"最低の最高気温\"と追記\n",
    "    * G2セルにデータの中で最低の気温を記録した地点名を追記\n",
    "    * H2セルにデータの中で最低の気温を記録した地点の気温を青色の文字で追記\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl \n",
    "\n",
    "filename = \"temperature.xlsx\"\n",
    "# Excelファイルを開く\n",
    "book = \n",
    "\n",
    "# アクティブになっているシートを得る\n",
    "sheet = \n",
    "\n",
    "# 最高・最低気温を検索する\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Excelに書き込む\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# フォントの設定を変更\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 書き込んだ内容を保存\n",
    "filename = \"exam11.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12\n",
    "以下の処理を行うプログラムを完成させなさい。\n",
    "* DB名\"exam12\"をTinyDBで作成し、テーブル\"temperature\"に次のデータを登録する\n",
    "    * 'name': '稚内', 'temperature': -0.6\n",
    "    * 'name': '旭川', 'temperature': 1.5\n",
    "    * 'name': '札幌', 'temperature': 3.1\n",
    "    * 'name': '根室', 'temperature': 0.5\n",
    "    * 'name': '網走', 'temperature': -1.2\n",
    "* 全データを抽出して表示する\n",
    "* 札幌のtemperatureを抽出して表示する\n",
    "* temperatureがマイナスのnameを抽出して表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "\n",
    "filepath = \"exam12.json\"\n",
    "# データベースに接続\n",
    "db = \n",
    "\n",
    "# 既存のデータがあれば破棄\n",
    "db.\n",
    "\n",
    "# テーブルを得る\n",
    "table = \n",
    "\n",
    "# データをデータベースに挿入\n",
    "table.\n",
    "table.\n",
    "table.\n",
    "table.\n",
    "table.\n",
    "\n",
    "# 全データを抽出して表示\n",
    "print(\"=== 全データ ===\")\n",
    "print(            )\n",
    "\n",
    "\n",
    "# 札幌のtemperatureを抽出して表示\n",
    "print(\"=== 札幌の気温 ===\")\n",
    "Item = \n",
    "res = \n",
    "print('札幌：',   )\n",
    "\n",
    "\n",
    "# temperatureがマイナスのnameを抽出\n",
    "print(\"=== 気温がマイナスの地点 ===\")\n",
    "res = \n",
    "for it in res:\n",
    "    print(\"-\",    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13\n",
    "下図はDjangoを用いたWebアプリの処理の流れを示したものである。  \n",
    "図中の①～⑦に当てはまる語句を解答しなさい。\n",
    "\n",
    "<img src=\".\\fig\\fig_13.png\" width=\"600\" alt=\"Django画像\">\n",
    "\n",
    "* ①～⑦の説明\n",
    "* ①： Webアプリ全体の構成単位\n",
    "* ②： Webアプリ中の機能単位でのまとまり\n",
    "* ③： URLからどの②や④に処理を渡すかを識別するコンポーネント\n",
    "* ④： ②の中で司令塔の役割を果たすコンポーネント\n",
    "* ⑤： 画面で入力された値のバリデーションや、入力された値をオブジェクトに変換してDjango内部で保持するためのコンポーネント\n",
    "* ⑥： データベースとの連携を受け持ち、データベースの更新や検索結果を返すコンポーネント\n",
    "* ⑦： HTMLのひな型にデータベースの処理結果などを埋め込み、HTMLを作成するコンポーネント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答欄\n",
    "* ① \n",
    "* ② \n",
    "* ③ \n",
    "* ④ \n",
    "* ⑤ \n",
    "* ⑥ \n",
    "* ⑦ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14\n",
    "Djangoのユーティリティコマンドについて説明している下記文章中の①～⑦に当てはまる語句を解答しなさい。\n",
    "* Djangoプロジェクトを作成するコマンド\n",
    "    * \\$ ① ② ＜プロジェクト名＞  \n",
    "* Djangoアプリケーションを作成するコマンド\n",
    "    * \\$ python manage.py ③ ＜アプリケーション名＞\n",
    "* 開発用サーバーの起動\n",
    "    * \\$ python manage.py ④\n",
    "* マイグレーションファイルの作成\n",
    "    * \\$ python manage.py ⑤\n",
    "* マイグレーションの実行\n",
    "    * \\$ python manage.py ⑥\n",
    "* スーパーユーザー（サイト管理者）の作成\n",
    "    * \\$ python manage.py ⑦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答欄\n",
    "* ① \n",
    "* ② \n",
    "* ③ \n",
    "* ④ \n",
    "* ⑤ \n",
    "* ⑥ \n",
    "* ⑦ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
